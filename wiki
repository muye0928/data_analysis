from bs4 import BeautifulSoup
from urllib.request import urlopen
import re
import random
his = ['/wiki/Yeshiva']
base_url = 'https://en.wikipedia.org'

for i in range(20):
    url = base_url + his[-1]
    html = urlopen(url).read()
    soup = BeautifulSoup(html, features='lxml')
    print(i, soup.find('h1').get_text(), 'url:', his[-1])
    
    sub_urls = soup.find_all('a',href = re.compile('\/wiki\/.+'))
    if len(sub_urls) != 0:
        his.append(random.sample(sub_urls,1)[0]['href'])    
    else:
        his.pop()
   
